#!/usr/bin/env python3
# encoding: utf-8

import requests
import json
import os.path
import time
import argparse

def get_quotes(url):
    resp = requests.get("{}/wp-json/posts?filter[orderby]=rand&filter[posts_per_page]=30".format(url))
    if resp.status_code != 200:
        raise Exception("Bad status code. status_code={}, body={}".format(resp.status_code, resp.body))
    try:
        return resp.json()
    except:
        print("Error parsing JSON")
        return None

def get_quote_key(quote):
    return quote['ID']

def scrape_quotes(url, filename):
    quotes = {}
    if os.path.isfile(filename):
        print("Loading contents from file.")
        with open(filename, 'r') as infile:
            quotes = json.load(infile)
        print("Qoutes: {}".format(len(quotes)))
    try:
        while True:
            quote = get_quotes(url)
            for q in quote:
                key = get_quote_key(q)
                quotes[key] = q
            print("Count={}".format(len(quotes)))
    except KeyboardInterrupt:
        pass
    except Exception:
        print("Finishing. Writing to file.")
        with open(filename, 'w') as outfile:
            json.dump(quotes, outfile)
        print("Qoutes: {}".format(len(quotes)))
        raise

    print("Finishing. Writing to file.")
    with open(filename, 'w') as outfile:
        json.dump(quotes, outfile)
    print("Qoutes: {}".format(len(quotes)))
    import pdb; pdb.set_trace()

if __name__ == "__main__":
    parser = argparse.ArgumentParser(description='Works with WordPress API')
    parser.add_argument('--site', action="store", help="Wordpress site to scrape")
    parser.add_argument('--file', action="store", help="JSON file to operate on")
    args = parser.parse_args()

    if args.site is None or args.file is None:
        parser.print_help()
        exit(1)
    scrape_quotes(args.site, args.file)
